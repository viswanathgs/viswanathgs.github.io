<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="/assets/css/main.css">
  <title>Viswanath (Vish) Sivakumar</title>
</head>
<body>
  <div class="header">
    <h1><a href="/">Viswanath (Vish) Sivakumar</a></h1>
    <div class="nav">
      <a href="/" class="active">home</a>
      <a href="/blog/">blog</a>
    </div>
  </div>
  
  <div class="content">
    <p><a href="https://github.com/viswanathgs">github</a> | <a href="https://linkedin.com/in/viswanathgs">linkedin</a> | <a href="/assets/resume.pdf">resume</a> | <a href="https://twitter.com/viswanathgs">twitter</a> | <a href="https://scholar.google.com/citations?user=hLPvq9AAAAAJ">scholar</a> | <a href="mailto:viswanathgs@gmail.com">email</a></p>

<p>Iâ€™m an AI Researcher, currently exploring independent directions.</p>

<p>Previously, I was at Meta for 13 years. From 2020-2025, I was a research lead in the Neural Interfaces Group at Meta Reality Labs pioneering human-AI input using <a href="https://www.meta.com/emerging-tech/emg-wearable-technology">wrist electromyography</a> (EMG), with a specific focus on decoding handwriting and typing. My work culminated in the launch of the <a href="https://www.meta.com/ai-glasses/meta-ray-ban-display-glasses-and-neural-band/">Meta Neural Band</a>, the first ever general-purpose consumer neural interface product, with a <a href="https://www.youtube.com/live/D97ILdUbYww?si=ClCg_DACoSjyMT4g&amp;t=3134">live demo</a> by Mark Zuckerberg, and has been published in <a href="https://www.nature.com/articles/s41586-025-09255-w">Nature</a> and <a href="https://ai.meta.com/blog/open-sourcing-surface-electromyography-datasets-neurips-2024">NeurIPS</a>. Prior to neural interfaces, I worked at Meta AI (FAIR) on vision, reinforcement learning, and ML systems.</p>

<p>I have had the good fortune of getting to experience living in SF, NYC, and London during my 20s. I currently reside in NYC.</p>

  </div>

</body>
</html>
